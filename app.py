from flask import Flask, request, abort
import sys
import json
import configparser
import typing
import os
import azure.cognitiveservices.speech as speechsdk
import librosa

# Line
from linebot.v3 import (WebhookHandler)
from linebot.v3.exceptions import (InvalidSignatureError)
from linebot.v3.webhooks import (
    MessageEvent,
    TextMessageContent,
    ImageMessageContent,
)
from linebot.v3.messaging import (Configuration, ApiClient, MessagingApi,
                                  ReplyMessageRequest, TextMessage,
                                  AudioMessage, ImageMessage, StickerMessage,
                                  MessagingApiBlob)

# Azure
from azure.core.credentials import AzureKeyCredential

# Azure Text Analytics
from azure.ai.textanalytics import TextAnalyticsClient

# Azure Translation
from azure.ai.translation.text import TextTranslationClient
from azure.ai.translation.text.models import InputTextItem
from azure.core.exceptions import HttpResponseError

# Gemini
from functions.gemini import gemini_generate, gemini_foodStringAnalyze, gemini_storyReview, gemini_foodExplainer, gemini_detectTranslationAndSpeech

# Azure
from functions.azure import azure_sentiment, azure_computer_vision, azure_translate, azure_speech

# Database
from db.mysql import connect_mysql, check_and_create_table
from crud.food_management import saveFoodRecordToDatabase, getAvailableFoodRecords
from crud.story_management import saveStoryToDatabase, getRandomStory
from functions.user import checkIsUserExistAndNeedLanguageSupportOrNot, switchUserNeedSpeech, switchUserNeedTranslation, switchUserPreferredLanguage

# è³‡æ–™åº«é…ç½®
db_config = {
    'user': 'root',
    'password': 'my-secret-pw',
    'host': 'localhost',
    'port': 3300,
    'database': 'test_db',
    'autocommit': True,  # Ensures immediate commit
    'connection_timeout': 1200,  # Set an appropriate timeout
    'charset': 'utf8mb4',
    'collation': 'utf8mb4_general_ci'
}

# Redis é…ç½®
redis_config = {'host': 'localhost', 'port': 6379, 'db': 0}

# æ¸¬è©¦è³‡æ–™åº«é€£æ¥
db_conn, db_cursor = connect_mysql(db_config)

# æª¢æŸ¥ä¸¦å‰µå»ºè³‡æ–™è¡¨--long_term_data
create_long_term_data_table_sql = """
CREATE TABLE long_term_data (
    id INT AUTO_INCREMENT PRIMARY KEY,
    date VARCHAR(255),
    date_chinese VARCHAR(255),
    day_of_week VARCHAR(255),
    supervision_area VARCHAR(255),
    supervision_unit VARCHAR(255),
    license_type VARCHAR(255),
    remaining_places INT,
    description TEXT,
    record_time DATETIME
)
"""
# check_and_create_table(db_cursor, 'long_term_data', create_long_term_data_table_sql)

# æª¢æŸ¥ä¸¦å‰µå»ºè³‡æ–™è¡¨--food_record
create_food_record = """
CREATE TABLE food_record (
    food VARCHAR(255),
    location VARCHAR(255),
    record_time DATETIME,
    validTime INT
)
"""
check_and_create_table(db_cursor, 'food_record', create_food_record)

# æª¢æŸ¥ä¸¦å‰µå»ºè³‡æ–™è¡¨--story_record
create_story_record = """
CREATE TABLE story_record (
    story_content TEXT,
    record_time DATETIME
)
"""
check_and_create_table(db_cursor, 'story_record', create_story_record)

# æª¢æŸ¥ä¸¦å‰µå»ºè³‡æ–™è¡¨--user_record
create_user_record = """
CREATE TABLE user_record (
    user_id VARCHAR(255),
    needTranslation BOOLEAN,
    needSpeech BOOLEAN,
    preferredLanguage VARCHAR(255)
)
"""
check_and_create_table(db_cursor, 'user_record', create_user_record)

# é—œé–‰è³‡æ–™åº«é€£æ¥
db_cursor.close()
db_conn.close()

# Config Parser
config = configparser.ConfigParser()
config.read('config.ini')

# Azure Speech Settings
speech_config = speechsdk.SpeechConfig(
    subscription=config['AzureSpeech']['SPEECH_KEY'],
    region=config['AzureSpeech']['SPEECH_REGION'])
audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)
UPLOAD_FOLDER = 'static'

# Translator Setup
text_translator = TextTranslationClient(
    credential=AzureKeyCredential(config["AzureTranslator"]["Key"]),
    endpoint=config["AzureTranslator"]["EndPoint"],
    region=config["AzureTranslator"]["Region"],
)

# Config Azure Analytics
analyticsCredential = AzureKeyCredential(
    config["AzureLanguage"]["LANGUAGE_KEY"])

# Flask
app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

# Line Bot
channel_access_token = config['Line']['CHANNEL_ACCESS_TOKEN']
channel_secret = config['Line']['CHANNEL_SECRET']
if channel_secret is None:
    print('Specify LINE_CHANNEL_SECRET as environment variable.')
    sys.exit(1)
if channel_access_token is None:
    print('Specify LINE_CHANNEL_ACCESS_TOKEN as environment variable.')
    sys.exit(1)
handler = WebhookHandler(channel_secret)
configuration = Configuration(access_token=channel_access_token)


@app.route("/callback", methods=['POST'])
def callback():
    # get X-Line-Signature header value
    signature = request.headers['X-Line-Signature']
    # get request body as text
    body = request.get_data(as_text=True)
    app.logger.info("Request body: " + body)

    # parse webhook body
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return 'OK'


@handler.add(MessageEvent, message=TextMessageContent)
def message_text(event):
    userInputMessage = event.message.text  # Get the user input message
    print(event)

    replyString = "test"  # Initialize the reply string
    audio_duration = 0  # Initialize the audio duration
    noSpeechAndTranslation = True  # Initialize the noSpeechAndTranslation flag

    userData = checkIsUserExistAndNeedLanguageSupportOrNot(
        event.source.user_id)
    print(userData)
    isNeedTranslation = userData[0]
    isNeedSpeech = userData[1]
    preferredLanguage = userData[2]

    # å¦‚æœä½¿ç”¨äº†é—œéµè©å€‘
    if (userInputMessage.startswith("/putfood")):
        # ç§»é™¤å‰é¢çš„"/putfood"
        userInputMessage = userInputMessage[8:]
        # å°‡å‰©ä¸‹çš„å­—ä¸²ä¸Ÿå…¥Geminiï¼Œä¸¦å–å¾—å›å‚³çš„JSONç‰©ä»¶
        newFoodObject = gemini_foodStringAnalyze(userInputMessage)
        # å°‡é€™ç­†è³‡æ–™å­˜å…¥MySQLèˆ‡Redis
        saveFoodRecordToDatabase(newFoodObject)
        # å›å‚³æˆåŠŸè¨Šæ¯
        replyString = "å·²è¨˜éŒ„ï¼æ„Ÿè¬ä½ çš„åˆ†äº«ğŸ§¡"
    elif (userInputMessage.startswith("/lovefood")):
        # å°‡redisä¸­çš„æ‰€æœ‰è³‡æ–™å–å‡º
        allAvailableFoodString = getAvailableFoodRecords()
        replyString = allAvailableFoodString
    elif (userInputMessage.startswith("/sharestory")):
        # ç§»é™¤å‰é¢çš„"/sharestory"
        userInputMessage = userInputMessage[11:]
        # å°‡å‰©ä¸‹çš„å­—ä¸²ä¸Ÿå…¥Geminiå–å¾—Geminiçš„å›æ‡‰
        geminiReview = gemini_storyReview(userInputMessage)
        azureReview = azure_sentiment(userInputMessage)
        storyToStore = "é€™æ˜¯æŸä½éå®¢çš„æ•…äº‹ï¼š\n" + userInputMessage + "\n\n" + "AIåˆ†æï¼š" + azureReview[
            0] + "\n\nAIå°è©±ç²¾éˆï¼š" + geminiReview
        # å°‡é€™ç­†æ•…äº‹å­˜å…¥MySQL
        saveStoryToDatabase(storyToStore)
        # å›å‚³æˆåŠŸè¨Šæ¯
        replyString = "å·²è¨˜éŒ„ï¼æ„Ÿè¬ä½ çš„åˆ†äº«ğŸ§¡"
    elif (userInputMessage.startswith("/listenstory")):
        # å¾MySQLä¸­éš¨æ©Ÿå–å‡ºä¸€ç­†æ•…äº‹
        randomStory = getRandomStory()
        replyString = randomStory
        if (isNeedSpeech):
            audio_duration = azure_speech(
                azure_translate(replyString, preferredLanguage),
                preferredLanguage)
        if (isNeedTranslation):
            replyString = replyString + '\n' + azure_translate(
                replyString, preferredLanguage)
    elif (userInputMessage.startswith("/speech")):
        # å°‡user_recordä¸­çš„needSpeechè¨­ç‚ºTrue
        if (switchUserNeedSpeech(event.source.user_id)):
            replyString = "å·²é–‹å•ŸèªéŸ³åŠŸèƒ½ï¼"
        else:
            replyString = "èªéŸ³åŠŸèƒ½å·²é—œé–‰ï¼"
    elif (userInputMessage.startswith("/translate")):
        if (switchUserNeedTranslation(event.source.user_id)):
            replyString = "å·²é–‹å•Ÿç¿»è­¯åŠŸèƒ½ï¼"
        else:
            replyString = "ç¿»è­¯åŠŸèƒ½å·²é—œé–‰ï¼"
    elif (userInputMessage.startswith("/language")):
        # ç§»é™¤å‰é¢çš„"/language"
        userInputMessage = userInputMessage[10:]
        if (userInputMessage == ""):
            replyString = "ä½ çš„åå¥½èªè¨€ç¾åœ¨æ˜¯ï¼š" + preferredLanguage
        else:
            currLanguage = switchUserPreferredLanguage(event.source.user_id,
                                                       userInputMessage)
            replyString = "å·²å°‡ä½ çš„åå¥½èªè¨€è¨­ç‚ºï¼š" + currLanguage

    # å¦‚æœæ²’æœ‰ä½¿ç”¨é—œéµè©
    # å…ˆèµ°ä¸€æ¬¡Azureçš„èªæ„åˆ†æ
    if (replyString == "test"):
        noSpeechAndTranslation = False
        setimentResult = azure_sentiment(userInputMessage)
        if (setimentResult[1] < 0.35):  # è² å‘
            replyString = gemini_generate(userInputMessage,
                                          "negative")  # èº«å¿ƒå¥åº·åˆ†æèˆ‡å»ºè­°
            if (isNeedSpeech):
                audio_duration = azure_speech(
                    azure_translate(replyString, preferredLanguage),
                    preferredLanguage)
            if (isNeedTranslation):
                replyString = replyString + '\n' + azure_translate(
                    replyString, preferredLanguage)
        else:
            replyString = gemini_generate(userInputMessage, "normal")  # ä¸€èˆ¬å°è©±
            if (isNeedSpeech):
                audio_duration = azure_speech(
                    azure_translate(replyString, preferredLanguage),
                    preferredLanguage)
            if (isNeedTranslation):
                replyString = replyString + '\n' + azure_translate(
                    replyString, preferredLanguage)

            # èˆŠæ–¹æ³•ï¼Œé€™æ–¹å¼æœ‰é»çˆ›ï¼Œæ£„ç”¨
            # detectionTS = gemini_detectTranslationAndSpeech(
            #     userInputMessage)  # ç¿»è­¯èˆ‡èªéŸ³
            # isNeedTranslation = detectionTS["isNeedTranslation"]
            # neededLanguage = detectionTS["neededLanguage"]
            # isNeedSpeech = detectionTS["isNeedSpeech"]
            # print(isNeedTranslation, neededLanguage, isNeedSpeech)

    # audio_duration = azure_speech(translatedMessage, inputLanguage)
    with ApiClient(configuration) as api_client:
        line_bot_api = MessagingApi(api_client)
        messages = [TextMessage(text=replyString)]
        if (isNeedSpeech and not noSpeechAndTranslation):  # å¦‚æœéœ€è¦èªéŸ³æœå‹™
            messages.append(
                AudioMessage(originalContentUrl=config["Deploy"]["URL"] +
                             "/static/outputaudio.wav",
                             duration=audio_duration))
        line_bot_api.reply_message_with_http_info(
            ReplyMessageRequest(reply_token=event.reply_token,
                                messages=messages))


@handler.add(MessageEvent, message=ImageMessageContent)
def message_image(event):
    userData = checkIsUserExistAndNeedLanguageSupportOrNot(
        event.source.user_id)
    isNeedTranslation = userData[0]
    isNeedSpeech = userData[1]
    preferredLanguage = userData[2]
    replyString = "test"
    audio_duration = 0
    with ApiClient(configuration) as api_client:
        line_bot_blob_api = MessagingApiBlob(api_client)
        message_content = line_bot_blob_api.get_message_content(
            message_id=event.message.id)
        message_content_copy = message_content
        contentAfterAzure = azure_computer_vision(message_content_copy)
        print(contentAfterAzure)
        geminiExplanaition = gemini_foodExplainer(contentAfterAzure)
        print(geminiExplanaition)
        replyString = geminiExplanaition
        if (isNeedSpeech):
            audio_duration = azure_speech(
                azure_translate(replyString, preferredLanguage),
                preferredLanguage)
        if (isNeedTranslation):
            replyString = replyString + '\n' + azure_translate(
                replyString, preferredLanguage)
        filename = "image" + str(count_files_in_folder("images") + 1)
        image_path = os.path.join("images", f"{filename}.jpg")
        with open(image_path, 'wb') as fd:
            fd.write(message_content)

        line_bot_api = MessagingApi(api_client)
        messages = [TextMessage(text=replyString)]
        if (isNeedSpeech):  # å¦‚æœéœ€è¦èªéŸ³æœå‹™
            messages.append(
                AudioMessage(originalContentUrl=config["Deploy"]["URL"] +
                             "/static/outputaudio.wav",
                             duration=audio_duration))
        line_bot_api.reply_message_with_http_info(
            ReplyMessageRequest(reply_token=event.reply_token,
                                messages=messages))


def count_files_in_folder(folder_path):
    """è¨ˆç®—æ–‡ä»¶å¤¾ä¸­çš„æ–‡ä»¶æ•¸é‡"""
    try:
        files = [
            f for f in os.listdir(folder_path)
            if os.path.isfile(os.path.join(folder_path, f))
        ]
        return len(files)
    except Exception as e:
        print(f"è®€å–æ–‡ä»¶å¤¾å¤±æ•—ï¼š{e}")
        return 0


# Start the Flask server
if __name__ == "__main__":
    app.run(port=5001, debug=True)
